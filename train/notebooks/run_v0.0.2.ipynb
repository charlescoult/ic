{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "518a0c58",
   "metadata": {},
   "source": [
    "# Model Generation for GBIF Fungi Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc8a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_ver = '0.0.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b411778a",
   "metadata": {},
   "source": [
    "## References\n",
    "* [Transfer Learning with Hub](https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub)\n",
    "* [`tf.data`: Build TensorFlow input pipelines](https://www.tensorflow.org/guide/data?hl=en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbff1eb9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a285c8a1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2c0f4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from keras.utils.layer_utils import count_params\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "# Set logging to output INFO level to standard output\n",
    "logging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"INFO\"))\n",
    "\n",
    "# Set tf logging level to WARN\n",
    "tf.get_logger().setLevel( 'WARN' )\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a639289",
   "metadata": {},
   "source": [
    "### Limit GPU memory allocation\n",
    "[Limiting GPU Memory Growth](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16845159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_memory_growth(limit=True):\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, limit)\n",
    "            logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            # Memory growth must be set before GPUs have been initialized\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10a47939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 2 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "limit_memory_growth()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b5090e",
   "metadata": {},
   "source": [
    "### Multi-GPU strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44e16631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy = tf.distribute.MirroredStrategy( devices = [ \"/gpu:0\", \"/gpu:1\" ] )\n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106e1972",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c19476",
   "metadata": {},
   "source": [
    "## `runs` DataFrame\n",
    "Keeps track of all runs performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60bdfc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_dir = '/media/data/runs'\n",
    "runs_hdf = 'runs.h5'\n",
    "runs_hdf_key = 'runs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2704ae3",
   "metadata": {},
   "source": [
    "## `run` Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043f8b0f",
   "metadata": {},
   "source": [
    "The `run` dictionary will keep track of this run's user-defined hyperparameters as well as generated parameters such as random seeds and file paths. This information will be saved in the `runs_hdf` specified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d702f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = {}\n",
    "# use a formatted timestamp as the run's ID\n",
    "run['id'] = datetime.datetime.now().strftime('%Y_%m_%d-%H_%M_%S')\n",
    "run['notebook_ver'] = notebook_ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7603b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/data/runs/2023_03_20-18_07_00'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the path of the directory where this run's files will be stored (metadata, saved model(s), etc.)\n",
    "run['path'] = os.path.join( runs_dir, str(run['id']) )\n",
    "run['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce638f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will overwrite existing run in dataframe with the same id if one exists\n",
    "# - allows updating as we go\n",
    "def save_run_metadata(\n",
    "    run,\n",
    "    index = 'id',\n",
    "):\n",
    "    # create df from run using json_normalize to flatten dict\n",
    "    run_df = pd.json_normalize( run )\n",
    "    run_df = run_df.set_index( index )\n",
    "\n",
    "    # create runs_df if it doesn't exist\n",
    "    runs_hdf_path = os.path.join( runs_dir, runs_hdf )\n",
    "    if ( not os.path.isfile( runs_hdf_path ) ):\n",
    "        pd.DataFrame().to_hdf( runs_hdf_path, runs_hdf_key )\n",
    "    \n",
    "    # read in the runs_hdf\n",
    "    runs_df = pd.read_hdf(\n",
    "        runs_hdf_path,\n",
    "        runs_hdf_key,\n",
    "    )\n",
    "    \n",
    "    # If a row for this run already exists, remove it\n",
    "    if ( run[ index ] in runs_df.index ):\n",
    "        runs_df = runs_df.drop( run[ index ] )\n",
    " \n",
    "    # Add the updated data\n",
    "    runs_df = pd.concat(\n",
    "        [ runs_df, run_df ],\n",
    "    )\n",
    "    \n",
    "    # save to file\n",
    "    runs_df.to_hdf( runs_hdf_path, runs_hdf_key )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7249fd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick print of current run information for debug\n",
    "def print_run_metadata( run ):\n",
    "    print( json.dumps( run, indent = 3 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37f84a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the run's path doesn't already exist and create it\n",
    "if (os.path.exists( run['path'] )):\n",
    "    logging.warn(\"Run path already exists!!\")\n",
    "    logging.warn(\" Overwriting: %s\" % run['path'])\n",
    "else:\n",
    "    os.makedirs( run['path'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c9606a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"id\": \"2023_03_20-18_07_00\",\n",
      "   \"notebook_ver\": \"0.0.2\",\n",
      "   \"path\": \"/media/data/runs/2023_03_20-18_07_00\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print_run_metadata( run )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae653da",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3105e4c2",
   "metadata": {},
   "source": [
    "## Enumerate Available Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c66022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        source,\n",
    "        input_dim,\n",
    "        preprocessor,\n",
    "    ):\n",
    "        self.source = source\n",
    "        self.input_dim = input_dim\n",
    "        self.preprocessor = preprocessor\n",
    "    \n",
    "base_models = {\n",
    "    'MobileNet_v2': BaseModel(\n",
    "        source = 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4',\n",
    "        input_dim = 224,\n",
    "        # https://www.tensorflow.org/hub/common_signatures/images#input\n",
    "        # The inputs pixel values are scaled between -1 and 1, sample-wise.\n",
    "        preprocessor = tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'Inception_v3': BaseModel(\n",
    "        source = 'https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4',\n",
    "        input_dim = 299,\n",
    "        # The inputs pixel values are scaled between -1 and 1, sample-wise.\n",
    "        preprocessor = tf.keras.applications.inception_v3.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'Inception_v3_iNaturalist': BaseModel(\n",
    "        source = 'https://tfhub.dev/google/inaturalist/inception_v3/feature_vector/5',\n",
    "        input_dim = 299,\n",
    "        # The inputs pixel values are scaled between -1 and 1, sample-wise.\n",
    "        preprocessor = tf.keras.applications.inception_v3.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'Xception': BaseModel(\n",
    "        source = tf.keras.applications.Xception,\n",
    "        input_dim = 299,\n",
    "        # The inputs pixel values are scaled between -1 and 1, sample-wise.\n",
    "        preprocessor = tf.keras.applications.xception.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'ResNet101': BaseModel(\n",
    "        source = tf.keras.applications.resnet.ResNet101,\n",
    "        input_dim = 224,\n",
    "        preprocessor = tf.keras.applications.resnet50.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'ResNet50': BaseModel(\n",
    "        source = tf.keras.applications.ResNet50,\n",
    "        input_dim = 224,\n",
    "        preprocessor = tf.keras.applications.resnet50.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'Inception_ResNet_v2': BaseModel(\n",
    "        source = tf.keras.applications.InceptionResNetV2,\n",
    "        input_dim = 299,\n",
    "        preprocessor = tf.keras.applications.inception_resnet_v2.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'EfficientNet_v2': BaseModel(\n",
    "        source = tf.keras.applications.efficientnet_v2.EfficientNetV2B0,\n",
    "        input_dim = 224,\n",
    "        # The preprocessing logic has been included in the EfficientNetV2\n",
    "        # model implementation. Users are no longer required to call this\n",
    "        # method to normalize the input data. This method does nothing and\n",
    "        # only kept as a placeholder to align the API surface between old\n",
    "        # and new version of model.\n",
    "        preprocessor = tf.keras.applications.efficientnet_v2.preprocess_input,\n",
    "    ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf8d406",
   "metadata": {},
   "source": [
    "## Enumerate Available Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15af0de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetHDFSource:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        path,\n",
    "        key,\n",
    "        col_filename = 'filename',\n",
    "        col_label = 'label',\n",
    "    ):\n",
    "        self.path = path\n",
    "        self.key = key\n",
    "        self.col_filename = col_filename\n",
    "        self.col_label = col_label\n",
    "\n",
    "datasets = {\n",
    "    'gbif': DatasetHDFSource(\n",
    "        '/media/data/gbif/clean_data.h5',\n",
    "        'media_merged_filtered-by-species_350pt',\n",
    "        col_label = 'acceptedScientificName',\n",
    "    ),\n",
    "    'cub': DatasetHDFSource(\n",
    "        '/media/data/cub/cub.h5',\n",
    "        'cub',\n",
    "        col_filename = 'file_path',\n",
    "        col_label = 'class_name',\n",
    "    ),\n",
    "    'flowers': DatasetHDFSource(\n",
    "        '/media/data/flowers/flowers.h5',\n",
    "        'flowers',\n",
    "        # col_filename = 'filename',\n",
    "        col_label = 'class',\n",
    "    ),\n",
    "}\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53c36c8",
   "metadata": {},
   "source": [
    "### Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e932f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.update( {\n",
    "    'batch_size': 32,\n",
    "    'max_epochs': 20,\n",
    "    'model': {\n",
    "        'base': 'Inception_v3_iNaturalist',\n",
    "        'classifier': {\n",
    "            # dropout % of dense layer(s) of classifier\n",
    "            'dropout': 0.2,\n",
    "            # normalize output with a softmax?\n",
    "            'output_normalize': False,\n",
    "        },\n",
    "        'learning_rate': 0.01, # Adam Optimizer\n",
    "        # label smoothing\n",
    "        'label_smoothing': 0.1,\n",
    "    },\n",
    "    'dataset': {\n",
    "        'data_augmentation': False,\n",
    "        # 'downsample': 'min' or a number indicating the max number of samples per class to allow\n",
    "        'downsample': None,\n",
    "        # 'downsample': 20,\n",
    "        # the key of the source described in `datasets`\n",
    "        # 'source': 'gbif',\n",
    "        'source': 'flowers',\n",
    "        # test split\n",
    "        'split_test': 0.05,\n",
    "        # val split\n",
    "        'split_val': 0.2,\n",
    "\n",
    "    },\n",
    "    'callbacks': {\n",
    "        'early_stopping': {\n",
    "            'monitor': 'val_loss',\n",
    "            'patience': 10,\n",
    "            'restore_best_weights': True,\n",
    "            'start_from_epoch': 5,\n",
    "        }\n",
    "    }\n",
    "} )\n",
    "\n",
    "# TODO: allow loading of model weights from a previous run using its ID\n",
    "load_weights = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3804c4e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10239/815296292.py:32: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['notebook_ver', 'path', 'model.base', 'dataset.downsample',\n",
      "       'dataset.source', 'callbacks.early_stopping.monitor',\n",
      "       'label_mapping_path', 'dataset.data_augmentation'],\n",
      "      dtype='object')]\n",
      "\n",
      "  runs_df.to_hdf( runs_hdf_path, runs_hdf_key )\n"
     ]
    }
   ],
   "source": [
    "save_run_metadata( run )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6595e67a",
   "metadata": {},
   "source": [
    "### Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e9b5d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = {}\n",
    "timer['start'] = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b5b5ac",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12133130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in source dataframe\n",
    "ds_df = pd.read_hdf(\n",
    "    datasets[ run['dataset']['source'] ].path,\n",
    "    datasets[ run['dataset']['source'] ].key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb506886",
   "metadata": {},
   "source": [
    "### Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4608af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label count: 5\n",
      "Datapoint count: 3670\n"
     ]
    }
   ],
   "source": [
    "ds_classes = ds_df[ datasets[ run['dataset']['source'] ].col_label ].unique().tolist()\n",
    "print('Label count: %d' % len(ds_classes))\n",
    "print('Datapoint count: %d' % len(ds_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c17dbad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_label_mapping(\n",
    "    label_mapping,\n",
    "    file_path = './label_mapping.json',\n",
    "):\n",
    "    with open( file_path, 'w' ) as f:\n",
    "        json.dump( label_mapping, f, indent = 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92876643",
   "metadata": {},
   "outputs": [],
   "source": [
    "run['label_mapping_path'] = os.path.join( run['path'], 'label_mapping.json' )\n",
    "save_label_mapping(\n",
    "    ds_classes,\n",
    "    file_path = run['label_mapping_path'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "828f1236",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_df_label_vc = ds_df[ datasets[ run['dataset']['source'] ].col_label ].value_counts()\n",
    "ds_df_label_vc = ds_df_label_vc.sort_values( ascending = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a9e3c4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dandelion     898\n",
       "tulips        799\n",
       "sunflowers    699\n",
       "roses         641\n",
       "daisy         633\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_df_label_vc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1cdc99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dandelion     898\n",
       "tulips        799\n",
       "sunflowers    699\n",
       "roses         641\n",
       "daisy         633\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_df_label_vc.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfb4981b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_df_label_vc.hist( bins = 50 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e853b53e",
   "metadata": {},
   "source": [
    "### Dataset Transformation\n",
    "(downsample, upsample, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8de0672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample to equal number of samples per class if downsample param is set\n",
    "if ( run['dataset']['downsample'] ):\n",
    "    # if downsample param is 'min', downsample all classes to the same number of\n",
    "    # samples as the class with the least samples\n",
    "    if ( run['dataset']['downsample'] == 'min' ):\n",
    "        ds_df_label_vc_min = ds_df_label_vc.min()\n",
    "        print('Downsampling to least number of samples per class: %d' % ds_df_label_vc_min)\n",
    "    else:\n",
    "        # manual override\n",
    "        if ( run['dataset']['downsample'] > 0 ):\n",
    "            print( 'Overriding samples per class to: %d' % run['dataset']['downsample'] )\n",
    "            ds_df_label_vc_min = run['dataset']['downsample']\n",
    "        else: raise Exception(\"dataset downsample invalid\")\n",
    "    \n",
    "    # downsample based on \n",
    "    ds_df_trans = ds_df.groupby( by = datasets[ run['dataset']['source'] ].col_label ).sample( n = ds_df_label_vc_min )\n",
    "    ds_df_trans[ datasets[ run['dataset']['source'] ].col_label ].value_counts()\n",
    "    # verifying that our downsampling worked - all classes should have the same value_count\n",
    "    print(ds_df_trans[ datasets[ run['dataset']['source'] ].col_label ].value_counts().value_counts())\n",
    "else:\n",
    "    ds_df_trans = ds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a66265",
   "metadata": {},
   "source": [
    "We have transformed the original dataset through downsampling to produce a dataset where all classes have the same number of datapoints as the class with the least amount of datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27c1d12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New datapoint count: 3670\n"
     ]
    }
   ],
   "source": [
    "print( 'New datapoint count: %d' % len(ds_df_trans) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d63aa1b",
   "metadata": {},
   "source": [
    "### Train, Validation, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6507235",
   "metadata": {},
   "outputs": [],
   "source": [
    "run['dataset']['split_test'] = 0.05\n",
    "run['dataset']['split_val'] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5d088d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random states for reproducability\n",
    "import random\n",
    "\n",
    "# [0, 2**32 - 1]\n",
    "run['dataset']['seed_split_test'] = random.randint( 0, 2**32 - 1 )\n",
    "run['dataset']['seed_split_val'] = random.randint( 0, 2**32 - 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "722fd1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "ds_df_train, ds_df_test = train_test_split(\n",
    "    ds_df_trans,\n",
    "    test_size = run['dataset']['split_test'],\n",
    "    stratify = ds_df_trans[[ datasets[ run['dataset']['source'] ].col_label ]],\n",
    "    random_state = run['dataset']['seed_split_test'],\n",
    ")\n",
    "\n",
    "# val\n",
    "ds_df_train, ds_df_val = train_test_split(\n",
    "    ds_df_train,\n",
    "    test_size = run['dataset']['split_val'],\n",
    "    stratify = ds_df_train[[ datasets[ run['dataset']['source'] ].col_label ]],\n",
    "    random_state = run['dataset']['seed_split_val'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e04a392",
   "metadata": {},
   "source": [
    "### Input Data Pipeline Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57fab483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(\n",
    "    filename,\n",
    "):\n",
    "    img_raw = tf.io.read_file( filename )\n",
    "    img_tensor = tf.image.decode_image(\n",
    "        img_raw,\n",
    "        dtype = tf.dtypes.float32,\n",
    "        channels = 3,\n",
    "        expand_animations = False,\n",
    "    )\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e9a3cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(\n",
    "    img_tensor,\n",
    "    input_dim,\n",
    "):\n",
    "    return tf.image.resize(\n",
    "        img_tensor,\n",
    "        [ input_dim, input_dim ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2635233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(\n",
    "    img_tensor,\n",
    "    preprocessor,\n",
    "):\n",
    "    return preprocessor( img_tensor )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c94708c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_label_encoder( label, mapping ):\n",
    "    # one_hot = label == mapping\n",
    "    # label_encoded = tf.argmax( one_hot )\n",
    "    # return label_encoded\n",
    "    return label == mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "848b3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(\n",
    "    label,\n",
    "    label_encoder,\n",
    "):\n",
    "    return label_encoder( label )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d3c05ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(\n",
    "    img_tensor,\n",
    "    augmentation_func,\n",
    "):\n",
    "    return augmentation_func( img_tensor, training = True )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21f1d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation function selection\n",
    "augmentation_functions = [\n",
    "    tf.keras.Sequential( [\n",
    "        tf.keras.layers.RandomFlip( \"horizontal_and_vertical\" ),\n",
    "        tf.keras.layers.RandomRotation( 0.2 ),\n",
    "    ] )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9237d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set augmentation_func to None if no augmentation is desired\n",
    "# augmentation_func = augmentation_functions[0]\n",
    "augmentation_func = augmentation_functions[0] if run['dataset']['data_augmentation'] else None\n",
    "\n",
    "# Determines if data augmentation should be done in the IDP or in the model\n",
    "# Data augmentation will\n",
    "data_augmentation_in_ds = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0021e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a buffersize equal to the length of the dataset\n",
    "shuffle_buffer_size = int( len( ds_df_train ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b5874d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate and save the shuffle random seed\n",
    "run['dataset']['seed_shuffle'] = tf.random.uniform(\n",
    "    shape = (),\n",
    "    dtype = tf.int64,\n",
    "    maxval = tf.int64.max,\n",
    ").numpy()\n",
    "# make it json serializable...\n",
    "run['dataset']['seed_shuffle'] = int( run['dataset']['seed_shuffle'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54a0222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determines if preprocessing should be done in the IDP or in the model\n",
    "preprocessing_in_ds = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ffc84037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charlescoult/.conda/envs/fungi/lib/python3.10/site-packages/numpy/core/numeric.py:2468: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    }
   ],
   "source": [
    "# label encoding\n",
    "# (img_tensor_resized_preprocessed, label_encoded)\n",
    "label_encoder = tf.keras.layers.StringLookup(\n",
    "    vocabulary = ds_classes,\n",
    "    # sparse = True,\n",
    "    output_mode = 'one_hot',\n",
    "    num_oov_indices = 0,\n",
    ")\n",
    "label_vocab = label_encoder.get_vocabulary()\n",
    "\n",
    "def make_idp(\n",
    "    filenames,\n",
    "    labels,\n",
    "    input_dim,\n",
    "    is_training = False,\n",
    "    batch_size = 32,\n",
    "    augmentation_func = None,\n",
    "):\n",
    "    ds = tf.data.Dataset.from_tensor_slices( (\n",
    "        filenames,\n",
    "        labels,\n",
    "    ) )\n",
    "\n",
    "    # if isTraining, shuffle\n",
    "    if ( is_training ):\n",
    "        ds = ds.shuffle(\n",
    "            buffer_size = shuffle_buffer_size,\n",
    "            seed = run['dataset']['seed_shuffle'],\n",
    "        )\n",
    "\n",
    "    # image loading\n",
    "    # (img_tensor, label)\n",
    "    ds = ds.map(\n",
    "        lambda filename, label: (\n",
    "            load_image(filename),\n",
    "            label,\n",
    "        ),\n",
    "        num_parallel_calls = AUTOTUNE,\n",
    "    )\n",
    "\n",
    "    # if isTraining and augmentation_func exists, use data augmentation\n",
    "    if ( is_training and data_augmentation_in_ds and augmentation_func ):\n",
    "        logging.info(\"Adding data augmentation.\")\n",
    "        ds = ds.map(\n",
    "            lambda img_tensor, label: (\n",
    "                data_augmentation(img_tensor, augmentation_func),\n",
    "                label,\n",
    "            ),\n",
    "            num_parallel_calls = AUTOTUNE,\n",
    "        )\n",
    "    \n",
    "    # image resizing\n",
    "    # (img_tensor_resized, label)\n",
    "    ds = ds.map(\n",
    "        lambda img_tensor, label: (\n",
    "            resize( img_tensor, input_dim ),\n",
    "            label,\n",
    "        ),\n",
    "        num_parallel_calls = AUTOTUNE,\n",
    "    )\n",
    "    \n",
    "    # image preprocessing\n",
    "    # (img_tensor_resized_preprocessed, label)\n",
    "    if ( preprocessing_in_ds ):\n",
    "        ds = ds.map(\n",
    "            lambda img_tensor_resized, label: (\n",
    "                preprocessing( img_tensor_resized, base_models[ run['model']['base'] ].preprocessor ),\n",
    "                label,\n",
    "            ),\n",
    "            num_parallel_calls = AUTOTUNE,\n",
    "        )\n",
    "\n",
    "\n",
    "    ds = ds.map(\n",
    "        lambda img_tensor_resized_preprocessed, label: (\n",
    "            img_tensor_resized_preprocessed,\n",
    "            # encode_label( label, label_encoder ),\n",
    "            encode_label( label, lambda x: my_label_encoder( x, ds_classes ) ),\n",
    "        ),\n",
    "        num_parallel_calls = AUTOTUNE,\n",
    "    )\n",
    "\n",
    "    # Batch\n",
    "    ds = ds.batch( batch_size )\n",
    "    \n",
    "    # Prefetch\n",
    "    ds = ds.prefetch( buffer_size = AUTOTUNE )\n",
    "    \n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbefbe53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/charlescoult/.conda/envs/fungi/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/charlescoult/.conda/envs/fungi/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "# IDP creation\n",
    "ds_idp_train = make_idp(\n",
    "    ds_df_train[ datasets[ run['dataset']['source'] ].col_filename ].values,\n",
    "    ds_df_train[ datasets[ run['dataset']['source'] ].col_label ].values,\n",
    "    input_dim = base_models[ run['model']['base'] ].input_dim,\n",
    "    is_training = True,\n",
    "    batch_size = run['batch_size'],\n",
    "    augmentation_func = augmentation_func,\n",
    ")\n",
    "\n",
    "ds_idp_val = make_idp(\n",
    "    ds_df_val[ datasets[ run['dataset']['source'] ].col_filename ].values,\n",
    "    ds_df_val[ datasets[ run['dataset']['source'] ].col_label ].values,\n",
    "    input_dim = base_models[ run['model']['base'] ].input_dim,\n",
    "    is_training = False,\n",
    "    batch_size = run['batch_size'],\n",
    "    # turned off by is_training = False anyway...\n",
    "    augmentation_func = None,\n",
    ")\n",
    "\n",
    "ds_idp_test = make_idp(\n",
    "    ds_df_test[ datasets[ run['dataset']['source'] ].col_filename ].values,\n",
    "    ds_df_test[ datasets[ run['dataset']['source'] ].col_label ].values,\n",
    "    input_dim = base_models[ run['model']['base'] ].input_dim,\n",
    "    is_training = False,\n",
    "    batch_size = run['batch_size'],\n",
    "    # turned off by is_training = False anyway...\n",
    "    augmentation_func = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de845ab",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aa7788",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a0c6376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a name that accurately describes the model building function or\n",
    "# the tfhub model (by url) that was passed\n",
    "def get_model_name( model_handle ):\n",
    "\n",
    "    if callable(model_handle):\n",
    "        return f'keras.applications/{model_handle.__name__}'\n",
    "    else:\n",
    "        split = model_handle.split('/')\n",
    "        return f'tfhub/{split[-5]}.{split[-4]}.{split[-3]}'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3acf9abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize full model\n",
    "with strategy.scope():\n",
    "    full_model = tf.keras.Sequential( name = \"full_model\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad741a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if preprocessing_in_ds, then input is assumed to be preprocessed correctly from input dataset pipeline (idp)\n",
    "# else, add preprocessing layer to model\n",
    "with strategy.scope():\n",
    "    if ( not preprocessing_in_ds ):\n",
    "        raise Exception('not yet implemented')\n",
    "        full_model.add(\n",
    "\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a91f6bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate base_model layer\n",
    "def gen_base_model_layer(\n",
    "    name,\n",
    "    source,\n",
    "    input_dim,\n",
    "    trainable = False,\n",
    "):\n",
    "    # If model_handle is a model building function, use that function\n",
    "    if callable( source ):\n",
    "        base_model = source(\n",
    "            include_top = False,\n",
    "            input_shape = ( input_dim, input_dim ) + (3,),\n",
    "            weights = 'imagenet',\n",
    "            # pooling = 'avg',\n",
    "        )\n",
    "\n",
    "    # otherwise build a layer from the tfhub url that was passed as a string\n",
    "    else:\n",
    "        base_model = hub.KerasLayer(\n",
    "            source,\n",
    "            input_shape = ( input_dim, input_dim ) + (3,),\n",
    "            name = name,\n",
    "        )\n",
    "    \n",
    "    base_model.trainable = trainable\n",
    "\n",
    "    return base_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa51aae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n",
      "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n"
     ]
    }
   ],
   "source": [
    "# Add base model to full_model\n",
    "with strategy.scope():\n",
    "    full_model.add( gen_base_model_layer(\n",
    "        name = get_model_name( base_models[ run['model']['base'] ].source ),\n",
    "        source = base_models[ run['model']['base'] ].source,\n",
    "        input_dim = base_models[ run['model']['base'] ].input_dim,\n",
    "        trainable = True,\n",
    "    ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "48d708e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate classifier\n",
    "def gen_classifier_model_layer(\n",
    "    num_classes,\n",
    "    dropout,\n",
    "    add_softmax = False,\n",
    "):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            num_classes,\n",
    "            # activation = 'softmax',\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        layers.Dropout(dropout),\n",
    "    )\n",
    "\n",
    "    if ( add_softmax ):\n",
    "        model.add(\n",
    "            layers.Activation(\"softmax\", dtype=\"float32\"),\n",
    "        )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6aa4dddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add classifier model to full_model\n",
    "# TODO allow selection between different classification models\n",
    "with strategy.scope():\n",
    "    full_model.add( gen_classifier_model_layer(\n",
    "        num_classes = len( ds_classes ),\n",
    "        dropout = run['model']['classifier']['dropout'],\n",
    "        add_softmax = run['model']['classifier']['output_normalize'],\n",
    "    ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65bf126",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5b6575",
   "metadata": {},
   "source": [
    "* Note regarding `thawed_base_model_layers` and full model architecture ([reference](https://stackoverflow.com/questions/64227483/what-is-the-right-way-to-gradually-unfreeze-layers-in-neural-network-while-learn))\n",
    "![image](https://i.stack.imgur.com/JLJqv.png)\n",
    "* [Another great reference](https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253c44ee",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0881edf",
   "metadata": {},
   "source": [
    "# Training Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ed107505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: allow loading of model weights from previous run\n",
    "load_weights = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b6bce53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "# Sparse vs non-sparse CCE https://www.kaggle.com/general/197993\n",
    "with strategy.scope():\n",
    "    full_model.compile(\n",
    "        optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate = run['model']['learning_rate']\n",
    "        ),\n",
    "        # loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        #     from_logits = True,\n",
    "        # ),\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "            from_logits = not run['model']['classifier']['output_normalize'],\n",
    "            label_smoothing = run['model']['label_smoothing'],\n",
    "        ),\n",
    "        metrics = [\n",
    "            'accuracy',\n",
    "            tf.keras.metrics.AUC(),\n",
    "            # tf.keras.metrics.SparseCategoricalCrossentropy(),\n",
    "            # tf.keras.metrics.SparseTopKCategoricalAccuracy(\n",
    "            #     k = 3,\n",
    "            #     name = \"Top3\",\n",
    "            # ),\n",
    "            # tf.keras.metrics.SparseTopKCategoricalAccuracy(\n",
    "            #     k = 10,\n",
    "            #     name=\"Top10\",\n",
    "            # ),\n",
    "            # tf.keras.metrics.CategoricalCrossentropy(),            \n",
    "            # tf.keras.metrics.TopKCategoricalAccuracy( k=3, name=\"Top3\" ),\n",
    "            # tf.keras.metrics.TopKCategoricalAccuracy( k=10, name=\"Top10\" ),\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9df29b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard logs\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir = run['path'],\n",
    "    histogram_freq = 1,\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    # monitor='val_sparse_categorical_accuracy',\n",
    "    monitor = run['callbacks']['early_stopping']['monitor'],\n",
    "    verbose = 1,\n",
    "    patience = run['callbacks']['early_stopping']['patience'],\n",
    "    # min_delta = 0.01, # defaults to 0.\n",
    "    restore_best_weights = run['callbacks']['early_stopping']['restore_best_weights'],\n",
    "    start_from_epoch = run['callbacks']['early_stopping']['start_from_epoch'],\n",
    "    # mode = 'min', # should be chosen correctly based on monitor value\n",
    ")\n",
    "\n",
    "# Model Checkpoints for saving best model weights\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    os.path.join( run['path'], 'best_model' ),\n",
    "    save_best_only = True,\n",
    "    monitor = 'val_loss',\n",
    "    verbose = 1,\n",
    "    # mode = 'min', # should be chosen correctly based on monitor value\n",
    ")\n",
    "\n",
    "class TimerCallback( tf.keras.callbacks.Callback ):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        metric_name = 'epoch_duration',\n",
    "    ):\n",
    "        self.__epoch_start = None\n",
    "        self.__metric_name = metric_name\n",
    "    \n",
    "    def on_epoch_begin(\n",
    "        self,\n",
    "        epoch,\n",
    "        logs = None,\n",
    "    ):\n",
    "        self.__epoch_start = datetime.datetime.utcnow()\n",
    "        \n",
    "    def on_epoch_end(\n",
    "        self,\n",
    "        epoch,\n",
    "        logs,\n",
    "    ):\n",
    "        logs[ self.__metric_name ] = ( datetime.datetime.utcnow() - self.__epoch_start ) / datetime.timedelta( milliseconds = 1 )\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    tensorboard_callback,\n",
    "    early_stopping_callback,\n",
    "    model_checkpoint_callback,\n",
    "    TimerCallback(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "229e58bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"id\": \"2023_03_20-18_07_00\",\n",
      "   \"notebook_ver\": \"0.0.2\",\n",
      "   \"path\": \"/media/data/runs/2023_03_20-18_07_00\",\n",
      "   \"batch_size\": 32,\n",
      "   \"max_epochs\": 20,\n",
      "   \"model\": {\n",
      "      \"base\": \"Inception_v3_iNaturalist\",\n",
      "      \"classifier\": {\n",
      "         \"dropout\": 0.2,\n",
      "         \"output_normalize\": false\n",
      "      },\n",
      "      \"learning_rate\": 0.01,\n",
      "      \"label_smoothing\": 0.1\n",
      "   },\n",
      "   \"dataset\": {\n",
      "      \"data_augmentation\": false,\n",
      "      \"downsample\": null,\n",
      "      \"source\": \"flowers\",\n",
      "      \"split_test\": 0.05,\n",
      "      \"split_val\": 0.1,\n",
      "      \"seed_split_test\": 1329823000,\n",
      "      \"seed_split_val\": 4195998833,\n",
      "      \"seed_shuffle\": 7812969471457678628\n",
      "   },\n",
      "   \"callbacks\": {\n",
      "      \"early_stopping\": {\n",
      "         \"monitor\": \"val_loss\",\n",
      "         \"patience\": 10,\n",
      "         \"restore_best_weights\": true,\n",
      "         \"start_from_epoch\": 5\n",
      "      }\n",
      "   },\n",
      "   \"label_mapping_path\": \"/media/data/runs/2023_03_20-18_07_00/label_mapping.json\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print_run_metadata( run )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5b5997ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10239/815296292.py:32: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['notebook_ver', 'path', 'model.base', 'dataset.downsample',\n",
      "       'dataset.source', 'callbacks.early_stopping.monitor',\n",
      "       'label_mapping_path', 'dataset.data_augmentation'],\n",
      "      dtype='object')]\n",
      "\n",
      "  runs_df.to_hdf( runs_hdf_path, runs_hdf_key )\n"
     ]
    }
   ],
   "source": [
    "save_run_metadata( run )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "510fdab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "99/99 [==============================] - ETA: 0s - loss: 3.1719 - accuracy: 0.2400 - auc: 0.5338\n",
      "Epoch 1: val_loss did not improve from inf\n",
      "99/99 [==============================] - 47s 176ms/step - loss: 3.1719 - accuracy: 0.2400 - auc: 0.5338 - val_loss: nan - val_accuracy: 0.2178 - val_auc: 0.5072 - epoch_duration: 46901.6370\n",
      "Epoch 2/20\n",
      "98/99 [============================>.] - ETA: 0s - loss: 2.7072 - accuracy: 0.2908 - auc: 0.5700\n",
      "Epoch 2: val_loss did not improve from inf\n",
      "99/99 [==============================] - 12s 122ms/step - loss: 2.7076 - accuracy: 0.2907 - auc: 0.5700 - val_loss: nan - val_accuracy: 0.2178 - val_auc: 0.5072 - epoch_duration: 12087.4760\n",
      "Epoch 3/20\n",
      "98/99 [============================>.] - ETA: 0s - loss: 2.4529 - accuracy: 0.3087 - auc: 0.5791\n",
      "Epoch 3: val_loss did not improve from inf\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 2.4528 - accuracy: 0.3089 - auc: 0.5791 - val_loss: nan - val_accuracy: 0.2120 - val_auc: 0.4984 - epoch_duration: 12226.7400\n",
      "Epoch 4/20\n",
      "98/99 [============================>.] - ETA: 0s - loss: 2.1344 - accuracy: 0.3571 - auc: 0.6394\n",
      "Epoch 4: val_loss did not improve from inf\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 2.1343 - accuracy: 0.3573 - auc: 0.6395 - val_loss: nan - val_accuracy: 0.2178 - val_auc: 0.5032 - epoch_duration: 12259.2470\n",
      "Epoch 5/20\n",
      "98/99 [============================>.] - ETA: 0s - loss: 2.0040 - accuracy: 0.3575 - auc: 0.6492\n",
      "Epoch 5: val_loss did not improve from inf\n",
      "99/99 [==============================] - 12s 125ms/step - loss: 2.0040 - accuracy: 0.3573 - auc: 0.6491 - val_loss: nan - val_accuracy: 0.2034 - val_auc: 0.5000 - epoch_duration: 12377.0860\n",
      "Epoch 6/20\n",
      "98/99 [============================>.] - ETA: 0s - loss: 1.8845 - accuracy: 0.3696 - auc: 0.6514\n",
      "Epoch 6: val_loss did not improve from inf\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 1.8845 - accuracy: 0.3695 - auc: 0.6514 - val_loss: nan - val_accuracy: 0.2178 - val_auc: 0.5036 - epoch_duration: 12262.5950\n",
      "Epoch 7/20\n",
      "98/99 [============================>.] - ETA: 0s - loss: 1.8872 - accuracy: 0.3683 - auc: 0.6468\n",
      "Epoch 7: val_loss did not improve from inf\n",
      "99/99 [==============================] - 12s 125ms/step - loss: 1.8874 - accuracy: 0.3682 - auc: 0.6468 - val_loss: nan - val_accuracy: 0.2120 - val_auc: 0.4964 - epoch_duration: 12388.2280\n",
      "Epoch 8/20\n",
      "98/99 [============================>.] - ETA: 0s - loss: 2.5736 - accuracy: 0.2637 - auc: 0.5393\n",
      "Epoch 8: val_loss did not improve from inf\n",
      "99/99 [==============================] - 12s 125ms/step - loss: 2.5738 - accuracy: 0.2636 - auc: 0.5393 - val_loss: nan - val_accuracy: 0.2178 - val_auc: 0.4982 - epoch_duration: 12423.6800\n",
      "Epoch 9/20\n",
      "98/99 [============================>.] - ETA: 0s - loss: 2.3641 - accuracy: 0.2975 - auc: 0.6033\n",
      "Epoch 9: val_loss did not improve from inf\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 2.3641 - accuracy: 0.2974 - auc: 0.6032 - val_loss: nan - val_accuracy: 0.2178 - val_auc: 0.5068 - epoch_duration: 12275.5630\n",
      "Epoch 10/20\n",
      "98/99 [============================>.] - ETA: 0s - loss: 2.0389 - accuracy: 0.3587 - auc: 0.6458\n",
      "Epoch 10: val_loss did not improve from inf\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 2.0390 - accuracy: 0.3586 - auc: 0.6457 - val_loss: nan - val_accuracy: 0.2034 - val_auc: 0.4991 - epoch_duration: 12281.9780\n",
      "Epoch 11/20\n",
      "98/99 [============================>.] - ETA: 0s - loss: 2.0421 - accuracy: 0.3989 - auc: 0.6809\n",
      "Epoch 11: val_loss did not improve from inf\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 2.0422 - accuracy: 0.3988 - auc: 0.6807 - val_loss: nan - val_accuracy: 0.2120 - val_auc: 0.4982 - epoch_duration: 12301.0690\n",
      "Epoch 12/20\n",
      "98/99 [============================>.] - ETA: 0s - loss: 1.9698 - accuracy: 0.4279 - auc: 0.6907\n",
      "Epoch 12: val_loss did not improve from inf\n",
      "99/99 [==============================] - 12s 125ms/step - loss: 1.9697 - accuracy: 0.4281 - auc: 0.6908 - val_loss: nan - val_accuracy: 0.2178 - val_auc: 0.5072 - epoch_duration: 12407.1930\n",
      "Epoch 13/20\n",
      "98/99 [============================>.] - ETA: 0s - loss: 1.9316 - accuracy: 0.4576 - auc: 0.6928\n",
      "Epoch 13: val_loss did not improve from inf\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 1.9320 - accuracy: 0.4574 - auc: 0.6926 - val_loss: nan - val_accuracy: 0.2092 - val_auc: 0.4928 - epoch_duration: 12312.0500\n",
      "Epoch 14/20\n",
      "98/99 [============================>.] - ETA: 0s - loss: 2.1161 - accuracy: 0.4308 - auc: 0.6768\n",
      "Epoch 14: val_loss did not improve from inf\n",
      "99/99 [==============================] - 12s 125ms/step - loss: 2.1159 - accuracy: 0.4310 - auc: 0.6770 - val_loss: nan - val_accuracy: 0.2120 - val_auc: 0.4982 - epoch_duration: 12373.1170\n",
      "Epoch 15/20\n",
      "98/99 [============================>.] - ETA: 0s - loss: 2.3006 - accuracy: 0.4088 - auc: 0.6742Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "Epoch 15: val_loss did not improve from inf\n",
      "99/99 [==============================] - 13s 127ms/step - loss: 2.3006 - accuracy: 0.4087 - auc: 0.6741 - val_loss: nan - val_accuracy: 0.2178 - val_auc: 0.5036 - epoch_duration: 12636.1460\n",
      "Epoch 15: early stopping\n",
      "Completed.\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "timer['train_start'] = time.perf_counter()\n",
    "\n",
    "try:\n",
    "    with strategy.scope():\n",
    "        history = full_model.fit(\n",
    "            ds_idp_train,\n",
    "            validation_data = ds_idp_val,\n",
    "            epochs = run['max_epochs'],\n",
    "            callbacks = callbacks,\n",
    "            # validation_freq=2,\n",
    "        )\n",
    "    pass\n",
    "except KeyboardInterrupt:\n",
    "    print('\\n\\nInterrupted...')\n",
    "    # run['interrupted'] = True\n",
    "else:\n",
    "    print('Completed.')\n",
    "    # run['interrupted'] = False\n",
    "    \n",
    "timer['train_end'] = time.perf_counter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ccc0051c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.48888257\n"
     ]
    }
   ],
   "source": [
    "run['time'] = timer['train_end'] - timer['train_start']\n",
    "print(run['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "91731c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10239/815296292.py:32: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['notebook_ver', 'path', 'model.base', 'dataset.downsample',\n",
      "       'dataset.source', 'callbacks.early_stopping.monitor',\n",
      "       'label_mapping_path', 'dataset.data_augmentation'],\n",
      "      dtype='object')]\n",
      "\n",
      "  runs_df.to_hdf( runs_hdf_path, runs_hdf_key )\n"
     ]
    }
   ],
   "source": [
    "save_run_metadata( run )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ab09e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"id\": \"2023_03_20-18_07_00\",\n",
      "   \"notebook_ver\": \"0.0.2\",\n",
      "   \"path\": \"/media/data/runs/2023_03_20-18_07_00\",\n",
      "   \"batch_size\": 32,\n",
      "   \"max_epochs\": 20,\n",
      "   \"model\": {\n",
      "      \"base\": \"Inception_v3_iNaturalist\",\n",
      "      \"classifier\": {\n",
      "         \"dropout\": 0.2,\n",
      "         \"output_normalize\": false\n",
      "      },\n",
      "      \"learning_rate\": 0.01,\n",
      "      \"label_smoothing\": 0.1\n",
      "   },\n",
      "   \"dataset\": {\n",
      "      \"data_augmentation\": false,\n",
      "      \"downsample\": null,\n",
      "      \"source\": \"flowers\",\n",
      "      \"split_test\": 0.05,\n",
      "      \"split_val\": 0.1,\n",
      "      \"seed_split_test\": 1329823000,\n",
      "      \"seed_split_val\": 4195998833,\n",
      "      \"seed_shuffle\": 7812969471457678628\n",
      "   },\n",
      "   \"callbacks\": {\n",
      "      \"early_stopping\": {\n",
      "         \"monitor\": \"val_loss\",\n",
      "         \"patience\": 10,\n",
      "         \"restore_best_weights\": true,\n",
      "         \"start_from_epoch\": 5\n",
      "      }\n",
      "   },\n",
      "   \"label_mapping_path\": \"/media/data/runs/2023_03_20-18_07_00/label_mapping.json\",\n",
      "   \"time\": 220.48888257\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print_run_metadata( run )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "829710e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( history.epoch )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b402c6",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6480267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.concatenate([y for x, y in ds_idp_test], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1e18185f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 234ms/step\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    predictions = full_model.predict(\n",
    "        ds_idp_test,\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a17eb50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = tf.math.confusion_matrix(\n",
    "    np.argmax( test_labels, axis=1),\n",
    "    np.argmax( predictions, axis=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6ebff06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "f1 = sklearn.metrics.f1_score(\n",
    "    np.argmax( test_labels, axis = 1 ),\n",
    "    np.argmax( predictions, axis = 1 ),\n",
    "    average = 'micro',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "91b187de",
   "metadata": {},
   "outputs": [],
   "source": [
    "run['scores'] = {\n",
    "    'f1': f1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f777c4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10239/815296292.py:32: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['notebook_ver', 'path', 'model.base', 'dataset.downsample',\n",
      "       'dataset.source', 'callbacks.early_stopping.monitor',\n",
      "       'label_mapping_path', 'dataset.data_augmentation'],\n",
      "      dtype='object')]\n",
      "\n",
      "  runs_df.to_hdf( runs_hdf_path, runs_hdf_key )\n"
     ]
    }
   ],
   "source": [
    "save_run_metadata( run )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "be548a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21739130434782608"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8c05478a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=int32, numpy=\n",
       "array([[40,  0,  0,  0,  0],\n",
       "       [45,  0,  0,  0,  0],\n",
       "       [32,  0,  0,  0,  0],\n",
       "       [35,  0,  0,  0,  0],\n",
       "       [32,  0,  0,  0,  0]], dtype=int32)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a969723e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-fungi]",
   "language": "python",
   "name": "conda-env-.conda-fungi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
