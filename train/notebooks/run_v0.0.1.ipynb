{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "518a0c58",
   "metadata": {},
   "source": [
    "# Model Generation for GBIF Fungi Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc8a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_ver = \"0.0.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b411778a",
   "metadata": {},
   "source": [
    "## References\n",
    "* [Transfer Learning with Hub](https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub)\n",
    "* [`tf.data`: Build TensorFlow input pipelines](https://www.tensorflow.org/guide/data?hl=en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbff1eb9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a285c8a1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2c0f4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from keras.utils.layer_utils import count_params\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "# Set logging to output INFO level to standard output\n",
    "logging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"INFO\"))\n",
    "\n",
    "# Set tf logging level to WARN\n",
    "tf.get_logger().setLevel( 'WARN' )\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a639289",
   "metadata": {},
   "source": [
    "### Limit GPU memory allocation\n",
    "[Limiting GPU Memory Growth](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16845159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_memory_growth(limit=True):\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, limit)\n",
    "            logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            # Memory growth must be set before GPUs have been initialized\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10a47939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 2 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "limit_memory_growth()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b5090e",
   "metadata": {},
   "source": [
    "### Multi-GPU strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44e16631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy = tf.distribute.MirroredStrategy( devices = [ \"/gpu:0\", \"/gpu:1\" ] )\n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106e1972",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c19476",
   "metadata": {},
   "source": [
    "## `runs` DataFrame\n",
    "Keeps track of all runs performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60bdfc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_dir = '/media/data/runs'\n",
    "runs_hdf = 'runs.h5'\n",
    "runs_hdf_key = 'runs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2704ae3",
   "metadata": {},
   "source": [
    "## `run` Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043f8b0f",
   "metadata": {},
   "source": [
    "The `run` dictionary will keep track of this run's user-defined hyperparameters as well as generated parameters such as random seeds and file paths. This information will be saved in the `runs_hdf` specified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d702f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = {}\n",
    "# use a formatted timestamp as the run's ID\n",
    "run['id'] = datetime.datetime.now().strftime('%Y_%m_%d-%H_%M_%S')\n",
    "run['notebook_ver'] = notebook_ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7603b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/data/runs/2023_03_19-16_34_48'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the path of the directory where this run's files will be stored (metadata, saved model(s), etc.)\n",
    "run['path'] = os.path.join( runs_dir, str(run['id']) )\n",
    "run['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce638f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will overwrite existing run in dataframe with the same id if one exists\n",
    "# - allows updating as we go\n",
    "def save_run_metadata(\n",
    "    run,\n",
    "    index = 'id',\n",
    "):\n",
    "    # create df from run using json_normalize to flatten dict\n",
    "    run_df = pd.json_normalize( run )\n",
    "    run_df = run_df.set_index( index )\n",
    "\n",
    "    # create runs_df if it doesn't exist\n",
    "    runs_hdf_path = os.path.join( runs_dir, runs_hdf )\n",
    "    if ( not os.path.isfile( runs_hdf_path ) ):\n",
    "        pd.DataFrame().to_hdf( runs_hdf_path, runs_hdf_key )\n",
    "    \n",
    "    # read in the runs_hdf\n",
    "    runs_df = pd.read_hdf(\n",
    "        runs_hdf_path,\n",
    "        runs_hdf_key,\n",
    "    )\n",
    "    \n",
    "    # If a row for this run already exists, remove it\n",
    "    if ( run[ index ] in runs_df.index ):\n",
    "        runs_df = runs_df.drop( run[ index ] )\n",
    " \n",
    "    # Add the updated data\n",
    "    runs_df = pd.concat(\n",
    "        [ runs_df, run_df ],\n",
    "    )\n",
    "    \n",
    "    # save to file\n",
    "    runs_df.to_hdf( runs_hdf_path, runs_hdf_key )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7249fd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick print of current run information for debug\n",
    "def print_run_metadata( run ):\n",
    "    print( json.dumps( run, indent = 3 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37f84a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the run's path doesn't already exist and create it\n",
    "if (os.path.exists( run['path'] )):\n",
    "    logging.warn(\"Run path already exists!!\")\n",
    "    logging.warn(\" Overwriting: %s\" % run['path'])\n",
    "else:\n",
    "    os.makedirs( run['path'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c9606a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"id\": \"2023_03_19-16_34_48\",\n",
      "   \"notebook_ver\": \"0.0.1\",\n",
      "   \"path\": \"/media/data/runs/2023_03_19-16_34_48\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print_run_metadata( run )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae653da",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3105e4c2",
   "metadata": {},
   "source": [
    "## Enumerate Available Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c66022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        source,\n",
    "        input_dim,\n",
    "        preprocessor,\n",
    "    ):\n",
    "        self.source = source\n",
    "        self.input_dim = input_dim\n",
    "        self.preprocessor = preprocessor\n",
    "    \n",
    "base_models = {\n",
    "    'MobileNet_v2': BaseModel(\n",
    "        source = 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4',\n",
    "        input_dim = 224,\n",
    "        # https://www.tensorflow.org/hub/common_signatures/images#input\n",
    "        # The inputs pixel values are scaled between -1 and 1, sample-wise.\n",
    "        preprocessor = tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'Inception_v3': BaseModel(\n",
    "        source = 'https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4',\n",
    "        input_dim = 299,\n",
    "        # The inputs pixel values are scaled between -1 and 1, sample-wise.\n",
    "        preprocessor = tf.keras.applications.inception_v3.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'Inception_v3_iNaturalist': BaseModel(\n",
    "        source = 'https://tfhub.dev/google/inaturalist/inception_v3/feature_vector/5',\n",
    "        input_dim = 299,\n",
    "        # The inputs pixel values are scaled between -1 and 1, sample-wise.\n",
    "        preprocessor = tf.keras.applications.inception_v3.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'Xception': BaseModel(\n",
    "        source = tf.keras.applications.Xception,\n",
    "        input_dim = 299,\n",
    "        # The inputs pixel values are scaled between -1 and 1, sample-wise.\n",
    "        preprocessor = tf.keras.applications.xception.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'ResNet101': BaseModel(\n",
    "        source = tf.keras.applications.resnet.ResNet101,\n",
    "        input_dim = 224,\n",
    "        preprocessor = tf.keras.applications.resnet50.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'ResNet50': BaseModel(\n",
    "        source = tf.keras.applications.ResNet50,\n",
    "        input_dim = 224,\n",
    "        preprocessor = tf.keras.applications.resnet50.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'Inception_ResNet_v2': BaseModel(\n",
    "        source = tf.keras.applications.InceptionResNetV2,\n",
    "        input_dim = 299,\n",
    "        preprocessor = tf.keras.applications.inception_resnet_v2.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'EfficientNet_v2': BaseModel(\n",
    "        source = tf.keras.applications.efficientnet_v2.EfficientNetV2B0,\n",
    "        input_dim = 224,\n",
    "        # The preprocessing logic has been included in the EfficientNetV2\n",
    "        # model implementation. Users are no longer required to call this\n",
    "        # method to normalize the input data. This method does nothing and\n",
    "        # only kept as a placeholder to align the API surface between old\n",
    "        # and new version of model.\n",
    "        preprocessor = tf.keras.applications.efficientnet_v2.preprocess_input,\n",
    "    ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf8d406",
   "metadata": {},
   "source": [
    "## Enumerate Available Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15af0de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetHDFSource:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        path,\n",
    "        key,\n",
    "        col_filename = 'filename',\n",
    "        col_label = 'label',\n",
    "    ):\n",
    "        self.path = path\n",
    "        self.key = key\n",
    "        self.col_filename = col_filename\n",
    "        self.col_label = col_label\n",
    "\n",
    "datasets = {\n",
    "    'gbif': DatasetHDFSource(\n",
    "        '/media/data/gbif/clean_data.h5',\n",
    "        'media_merged_filtered-by-species_350pt',\n",
    "        col_label = 'acceptedScientificName',\n",
    "    ),\n",
    "    'cub': DatasetHDFSource(\n",
    "        '/media/data/cub/cub.h5',\n",
    "        'cub',\n",
    "        col_filename = 'file_path',\n",
    "        col_label = 'class_name',\n",
    "    ),\n",
    "}\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53c36c8",
   "metadata": {},
   "source": [
    "### Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e932f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.update( {\n",
    "    'batch_size': 32,\n",
    "    'max_epochs': 20,\n",
    "    'label_smoothing': 0.1,\n",
    "    'model': {\n",
    "        'base': 'Inception_v3_iNaturalist',\n",
    "        'classifier': {\n",
    "            'dropout': 0.33,\n",
    "            'output_logits': True\n",
    "        },\n",
    "        'learning_rate': 0.0005, # Adam Optimizer\n",
    "    },\n",
    "    \"dataset\": {\n",
    "        \"downsample\": \"min\",\n",
    "        \"source\": \"gbif\",\n",
    "        \"split_test\": 0.05,\n",
    "        \"split_val\": 0.1,\n",
    "\n",
    "    },\n",
    "    \"callbacks\": {\n",
    "        \"early_stopping\": {\n",
    "            'monitor': 'val_loss',\n",
    "            'patience': 10,\n",
    "            \"restore_best_weights\": True,\n",
    "            'start_from_epoch': 5,\n",
    "        }\n",
    "    }\n",
    "} )\n",
    "\n",
    "# TODO: allow loading of model weights from previous run\n",
    "load_weights = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3804c4e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12476/3436063570.py:32: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['notebook_ver', 'path', 'model.base', 'dataset.downsample',\n",
      "       'dataset.source', 'label_mapping_path'],\n",
      "      dtype='object')]\n",
      "\n",
      "  runs_df.to_hdf( runs_hdf_path, runs_hdf_key )\n"
     ]
    }
   ],
   "source": [
    "save_run_metadata( run )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6595e67a",
   "metadata": {},
   "source": [
    "### Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e9b5d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = {}\n",
    "timer['start'] = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b5b5ac",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12133130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in source dataframe\n",
    "ds_df = pd.read_hdf(\n",
    "    datasets[ run['dataset']['source'] ].path,\n",
    "    datasets[ run['dataset']['source'] ].key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb506886",
   "metadata": {},
   "source": [
    "### Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4608af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label count: 2451\n",
      "Datapoint count: 665803\n"
     ]
    }
   ],
   "source": [
    "ds_classes = ds_df[ datasets[ run['dataset']['source'] ].col_label ].unique().tolist()\n",
    "print('Label count: %d' % len(ds_classes))\n",
    "print('Datapoint count: %d' % len(ds_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c17dbad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_label_mapping(\n",
    "    label_mapping,\n",
    "    file_path = './label_mapping.json',\n",
    "):\n",
    "    with open( file_path, 'w' ) as f:\n",
    "        json.dump( label_mapping, f, indent = 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92876643",
   "metadata": {},
   "outputs": [],
   "source": [
    "run['label_mapping_path'] = os.path.join( run['path'], 'label_mapping.json' )\n",
    "save_label_mapping(\n",
    "    ds_classes,\n",
    "    file_path = run['label_mapping_path'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "828f1236",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_df_label_vc = ds_df[ datasets[ run['dataset']['source'] ].col_label ].value_counts()\n",
    "ds_df_label_vc = ds_df_label_vc.sort_values( ascending = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a9e3c4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Amanita muscaria (L.) Lam.              1050\n",
       "Pisolithus arhizus (Scop.) Rauschert    1050\n",
       "Phellinus igniarius (L.) Quél.          1030\n",
       "Inonotus obliquus (Fr.) Pilát            968\n",
       "Collybiopsis (J.Schröt.) Earle, 1909     942\n",
       "Name: acceptedScientificName, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_df_label_vc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1cdc99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cheimonophyllum candidissimum (Berk. & M.A.Curtis) Singer                                    101\n",
       "Urocystis anemones (Pers.) G.Winter                                                          101\n",
       "Melanelixia subargentifera (Nyl.) O.Blanco, A.Crespo, Divakar, Essl., D.Hawksw. & Lumbsch    101\n",
       "Furia ithacensis (J.P.Kramer) Humber                                                         101\n",
       "Fistulina antarctica Speg.                                                                   101\n",
       "Name: acceptedScientificName, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_df_label_vc.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfb4981b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_df_label_vc.hist( bins = 50 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abf9357",
   "metadata": {},
   "source": [
    "Most classes have 350 datapoints because I *thought* I had downsampled the datasets with more than 350 datapoints down to 350 but it looks like there are some that were not affected by the transformation I performed. There are some classes with more than 350 datapoints somehow. Regardless, we will be downsampling them all to the lowest value_count (101)..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e853b53e",
   "metadata": {},
   "source": [
    "### Dataset Transformation\n",
    "(downsample, upsample, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8de0672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampling to least number of samples per class: 101\n"
     ]
    }
   ],
   "source": [
    "# Downsample to equal number of samples per class if downsample param is set\n",
    "if ( run['dataset']['downsample'] ):\n",
    "    # if downsample param is 'min', downsample all classes to the same number of\n",
    "    # samples as the class with the least samples\n",
    "    if ( run['dataset']['downsample'] == 'min' ):\n",
    "        ds_df_label_vc_min = ds_df_label_vc.min()\n",
    "        print('Downsampling to least number of samples per class: %d' % ds_df_label_vc_min)\n",
    "    else:\n",
    "        # manual override\n",
    "        if ( run['dataset']['downsample'] > 0 ):\n",
    "            print( 'Overriding samples per class to: %d' % run['dataset']['downsample'] )\n",
    "            ds_df_label_vc_min = run['dataset']['downsample']\n",
    "        else: raise Exception(\"dataset downsample invalid\")\n",
    "    \n",
    "    # downsample based on \n",
    "    ds_df_trans = ds_df.groupby( by = datasets[ run['dataset']['source'] ].col_label ).sample( n = ds_df_label_vc_min )\n",
    "    ds_df_trans[ datasets[ run['dataset']['source'] ].col_label ].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bb10a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101    2451\n",
       "Name: acceptedScientificName, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying that our downsampling worked - all classes should have the same value_count\n",
    "ds_df_trans[ datasets[ run['dataset']['source'] ].col_label ].value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a66265",
   "metadata": {},
   "source": [
    "We have transformed the original dataset through downsampling to produce a dataset where all classes have the same number of datapoints as the class with the least amount of datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27c1d12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New datapoint count: 247551\n"
     ]
    }
   ],
   "source": [
    "print( 'New datapoint count: %d' % len(ds_df_trans) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d63aa1b",
   "metadata": {},
   "source": [
    "### Train, Validation, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6507235",
   "metadata": {},
   "outputs": [],
   "source": [
    "run['dataset']['split_test'] = 0.05\n",
    "run['dataset']['split_val'] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5d088d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random states for reproducability\n",
    "import random\n",
    "\n",
    "# [0, 2**32 - 1]\n",
    "run['dataset']['seed_split_test'] = random.randint( 0, 2**32 - 1 )\n",
    "run['dataset']['seed_split_val'] = random.randint( 0, 2**32 - 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "722fd1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "ds_df_train, ds_df_test = train_test_split(\n",
    "    ds_df_trans,\n",
    "    test_size = run['dataset']['split_test'],\n",
    "    stratify = ds_df_trans[[ datasets[ run['dataset']['source'] ].col_label ]],\n",
    "    random_state = run['dataset']['seed_split_test'],\n",
    ")\n",
    "\n",
    "# val\n",
    "ds_df_train, ds_df_val = train_test_split(\n",
    "    ds_df_train,\n",
    "    test_size = run['dataset']['split_val'],\n",
    "    stratify = ds_df_train[[ datasets[ run['dataset']['source'] ].col_label ]],\n",
    "    random_state = run['dataset']['seed_split_val'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e04a392",
   "metadata": {},
   "source": [
    "### Input Data Pipeline Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57fab483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(\n",
    "    filename,\n",
    "):\n",
    "    img_raw = tf.io.read_file( filename )\n",
    "    img_tensor = tf.image.decode_image(\n",
    "        img_raw,\n",
    "        dtype = tf.dtypes.float32,\n",
    "        channels = 3,\n",
    "        expand_animations = False,\n",
    "    )\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e9a3cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(\n",
    "    img_tensor,\n",
    "    input_dim,\n",
    "):\n",
    "    return tf.image.resize(\n",
    "        img_tensor,\n",
    "        [ input_dim, input_dim ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2635233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(\n",
    "    img_tensor,\n",
    "    preprocessor,\n",
    "):\n",
    "    return preprocessor( img_tensor )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c94708c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_label_encoder( label, mapping ):\n",
    "    one_hot = label == mapping\n",
    "    label_encoded = tf.argmax( one_hot )\n",
    "    return label_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "848b3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(\n",
    "    label,\n",
    "    label_encoder,\n",
    "):\n",
    "    return label_encoder( label )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d3c05ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(\n",
    "    img_tensor,\n",
    "    augmentation_func,\n",
    "):\n",
    "    return augmentation_func( img_tensor, training = True )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21f1d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation function selection\n",
    "augmentation_functions = [\n",
    "    tf.keras.Sequential( [\n",
    "        tf.keras.layers.RandomFlip( \"horizontal_and_vertical\" ),\n",
    "        tf.keras.layers.RandomRotation( 0.2 ),\n",
    "    ] )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9237d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set augmentation_func to None if no augmentation is desired\n",
    "# augmentation_func = augmentation_functions[0]\n",
    "augmentation_func = None\n",
    "\n",
    "# Determines if data augmentation should be done in the IDP or in the model\n",
    "# Data augmentation will\n",
    "data_augmentation_in_ds = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0021e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a buffersize equal to the length of the dataset\n",
    "shuffle_buffer_size = int( len( ds_df_train ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b5874d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate and save the shuffle random seed\n",
    "run['dataset']['seed_shuffle'] = tf.random.uniform(\n",
    "    shape = (),\n",
    "    dtype = tf.int64,\n",
    "    maxval = tf.int64.max,\n",
    ").numpy()\n",
    "# make it json serializable...\n",
    "run['dataset']['seed_shuffle'] = int( run['dataset']['seed_shuffle'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54a0222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determines if preprocessing should be done in the IDP or in the model\n",
    "preprocessing_in_ds = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ffc84037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charlescoult/.conda/envs/fungi/lib/python3.10/site-packages/numpy/core/numeric.py:2468: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    }
   ],
   "source": [
    "# label encoding\n",
    "# (img_tensor_resized_preprocessed, label_encoded)\n",
    "label_encoder = tf.keras.layers.StringLookup(\n",
    "    vocabulary = ds_classes,\n",
    "    # sparse = True,\n",
    "    output_mode = 'one_hot',\n",
    "    num_oov_indices = 0,\n",
    ")\n",
    "\n",
    "def make_idp(\n",
    "    filenames,\n",
    "    labels,\n",
    "    input_dim,\n",
    "    is_training = False,\n",
    "    batch_size = 32,\n",
    "    augmentation_func = None,\n",
    "):\n",
    "    ds = tf.data.Dataset.from_tensor_slices( (\n",
    "        filenames,\n",
    "        labels,\n",
    "    ) )\n",
    "\n",
    "    # if isTraining, shuffle\n",
    "    if ( is_training ):\n",
    "        ds = ds.shuffle(\n",
    "            buffer_size = shuffle_buffer_size,\n",
    "            seed = run['dataset']['seed_shuffle'],\n",
    "        )\n",
    "\n",
    "    # image loading\n",
    "    # (img_tensor, label)\n",
    "    ds = ds.map(\n",
    "        lambda filename, label: (\n",
    "            load_image(filename),\n",
    "            label,\n",
    "        ),\n",
    "        num_parallel_calls = AUTOTUNE,\n",
    "    )\n",
    "\n",
    "    # if isTraining and augmentation_func exists, use data augmentation\n",
    "    if ( is_training and data_augmentation_in_ds and augmentation_func ):\n",
    "        logging.info(\"Adding data augmentation.\")\n",
    "        ds = ds.map(\n",
    "            lambda img_tensor, label: (\n",
    "                data_augmentation(img_tensor, augmentation_func),\n",
    "                label,\n",
    "            ),\n",
    "            num_parallel_calls = AUTOTUNE,\n",
    "        )\n",
    "    \n",
    "    # image resizing\n",
    "    # (img_tensor_resized, label)\n",
    "    ds = ds.map(\n",
    "        lambda img_tensor, label: (\n",
    "            resize( img_tensor, input_dim ),\n",
    "            label,\n",
    "        ),\n",
    "        num_parallel_calls = AUTOTUNE,\n",
    "    )\n",
    "    \n",
    "    # image preprocessing\n",
    "    # (img_tensor_resized_preprocessed, label)\n",
    "    if ( preprocessing_in_ds ):\n",
    "        ds = ds.map(\n",
    "            lambda img_tensor_resized, label: (\n",
    "                preprocessing( img_tensor_resized, base_models[ run['model']['base'] ].preprocessor ),\n",
    "                label,\n",
    "            ),\n",
    "            num_parallel_calls = AUTOTUNE,\n",
    "        )\n",
    "\n",
    "\n",
    "    ds = ds.map(\n",
    "        lambda img_tensor_resized_preprocessed, label: (\n",
    "            img_tensor_resized_preprocessed,\n",
    "            encode_label( label, label_encoder ),\n",
    "            # encode_label( label, lambda x: my_label_encoder( x, ds_classes ) ),\n",
    "        ),\n",
    "        num_parallel_calls = AUTOTUNE,\n",
    "    )\n",
    "\n",
    "    # Batch\n",
    "    ds = ds.batch( batch_size )\n",
    "    \n",
    "    # Prefetch\n",
    "    ds = ds.prefetch( buffer_size = AUTOTUNE )\n",
    "    \n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dbefbe53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/charlescoult/.conda/envs/fungi/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/charlescoult/.conda/envs/fungi/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "# IDP creation\n",
    "ds_idp_train = make_idp(\n",
    "    ds_df_train[ datasets[ run['dataset']['source'] ].col_filename ].values,\n",
    "    ds_df_train[ datasets[ run['dataset']['source'] ].col_label ].values,\n",
    "    input_dim = base_models[ run['model']['base'] ].input_dim,\n",
    "    is_training = True,\n",
    "    batch_size = run['batch_size'],\n",
    "    augmentation_func = augmentation_func if ( augmentation_func ) else None,\n",
    ")\n",
    "\n",
    "ds_idp_val = make_idp(\n",
    "    ds_df_val[ datasets[ run['dataset']['source'] ].col_filename ].values,\n",
    "    ds_df_val[ datasets[ run['dataset']['source'] ].col_label ].values,\n",
    "    input_dim = base_models[ run['model']['base'] ].input_dim,\n",
    "    is_training = False,\n",
    "    batch_size = run['batch_size'],\n",
    "    # turned off by is_training = False anyway...\n",
    "    augmentation_func = None,\n",
    ")\n",
    "\n",
    "ds_idp_test = make_idp(\n",
    "    ds_df_test[ datasets[ run['dataset']['source'] ].col_filename ].values,\n",
    "    ds_df_test[ datasets[ run['dataset']['source'] ].col_label ].values,\n",
    "    input_dim = base_models[ run['model']['base'] ].input_dim,\n",
    "    is_training = False,\n",
    "    batch_size = run['batch_size'],\n",
    "    # turned off by is_training = False anyway...\n",
    "    augmentation_func = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de845ab",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aa7788",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9a0c6376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a name that accurately describes the model building function or\n",
    "# the tfhub model (by url) that was passed\n",
    "def get_model_name( model_handle ):\n",
    "\n",
    "    if callable(model_handle):\n",
    "        return f'keras.applications/{model_handle.__name__}'\n",
    "    else:\n",
    "        split = model_handle.split('/')\n",
    "        return f'tfhub/{split[-5]}.{split[-4]}.{split[-3]}'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3acf9abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize full model\n",
    "with strategy.scope():\n",
    "    full_model = tf.keras.Sequential( name = \"full_model\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad741a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if preprocessing_in_ds, then input is assumed to be preprocessed correctly from input dataset pipeline (idp)\n",
    "# else, add preprocessing layer to model\n",
    "with strategy.scope():\n",
    "    if ( not preprocessing_in_ds ):\n",
    "        raise Exception('not yet implemented')\n",
    "        full_model.add(\n",
    "\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a91f6bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate base_model layer\n",
    "def gen_base_model_layer(\n",
    "    name,\n",
    "    source,\n",
    "    input_dim,\n",
    "    trainable = False,\n",
    "):\n",
    "    # If model_handle is a model building function, use that function\n",
    "    if callable( source ):\n",
    "        base_model = source(\n",
    "            include_top = False,\n",
    "            input_shape = ( input_dim, input_dim ) + (3,),\n",
    "            weights = 'imagenet',\n",
    "            # pooling = 'avg',\n",
    "        )\n",
    "\n",
    "    # otherwise build a layer from the tfhub url that was passed as a string\n",
    "    else:\n",
    "        base_model = hub.KerasLayer(\n",
    "            source,\n",
    "            input_shape = ( input_dim, input_dim ) + (3,),\n",
    "            name = name,\n",
    "        )\n",
    "    \n",
    "    base_model.trainable = trainable\n",
    "\n",
    "    return base_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fa51aae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n",
      "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n"
     ]
    }
   ],
   "source": [
    "# Add base model to full_model\n",
    "with strategy.scope():\n",
    "    full_model.add( gen_base_model_layer(\n",
    "        name = get_model_name( base_models[ run['model']['base'] ].source ),\n",
    "        source = base_models[ run['model']['base'] ].source,\n",
    "        input_dim = base_models[ run['model']['base'] ].input_dim,\n",
    "        trainable = True,\n",
    "    ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "48d708e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate classifier\n",
    "def gen_classifier_model_layer(\n",
    "    num_classes,\n",
    "    dropout,\n",
    "    add_softmax = False,\n",
    "):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            num_classes,\n",
    "            # activation = 'softmax',\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        layers.Dropout(dropout),\n",
    "    )\n",
    "\n",
    "    if ( add_softmax ):\n",
    "        model.add(\n",
    "            layers.Activation(\"softmax\", dtype=\"float32\"),\n",
    "        )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6aa4dddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "run['model']['classifier']['output_logits'] = True\n",
    "# Add classifier model to full_model\n",
    "# TODO allow selection between different classification models\n",
    "with strategy.scope():\n",
    "    full_model.add( gen_classifier_model_layer(\n",
    "        num_classes = len( ds_classes ),\n",
    "        dropout = run['model']['classifier']['dropout'],\n",
    "        add_softmax = not run['model']['classifier']['output_logits'],\n",
    "    ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65bf126",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5b6575",
   "metadata": {},
   "source": [
    "* Note regarding `thawed_base_model_layers` and full model architecture ([reference](https://stackoverflow.com/questions/64227483/what-is-the-right-way-to-gradually-unfreeze-layers-in-neural-network-while-learn))\n",
    "![image](https://i.stack.imgur.com/JLJqv.png)\n",
    "* [Another great reference](https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253c44ee",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0881edf",
   "metadata": {},
   "source": [
    "# Training Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed107505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: allow loading of model weights from previous run\n",
    "load_weights = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6bce53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "# Sparse vs non-sparse CCE https://www.kaggle.com/general/197993\n",
    "with strategy.scope():\n",
    "    full_model.compile(\n",
    "        optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate = run['model']['learning_rate']\n",
    "        ),\n",
    "        # loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        #     from_logits = True,\n",
    "        # ),\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "            from_logits = run['model']['classifier']['output_logits'],\n",
    "            label_smoothing = run['label_smoothing'],\n",
    "        ),\n",
    "        metrics = [\n",
    "            'accuracy',\n",
    "            tf.keras.metrics.AUC(),\n",
    "            # tf.keras.metrics.SparseCategoricalCrossentropy(),\n",
    "            # tf.keras.metrics.SparseTopKCategoricalAccuracy(\n",
    "            #     k = 3,\n",
    "            #     name = \"Top3\",\n",
    "            # ),\n",
    "            # tf.keras.metrics.SparseTopKCategoricalAccuracy(\n",
    "            #     k = 10,\n",
    "            #     name=\"Top10\",\n",
    "            # ),\n",
    "            # tf.keras.metrics.CategoricalCrossentropy(),            \n",
    "            # tf.keras.metrics.TopKCategoricalAccuracy( k=3, name=\"Top3\" ),\n",
    "            # tf.keras.metrics.TopKCategoricalAccuracy( k=10, name=\"Top10\" ),\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9df29b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard logs\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir = run['path'],\n",
    "    histogram_freq = 1,\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    # monitor='val_sparse_categorical_accuracy',\n",
    "    monitor = run['callbacks']['early_stopping']['monitor'],\n",
    "    verbose = 1,\n",
    "    patience = run['callbacks']['early_stopping']['patience'],\n",
    "    # min_delta = 0.01, # defaults to 0.\n",
    "    restore_best_weights = run['callbacks']['early_stopping']['restore_best_weights'],\n",
    "    start_from_epoch = run['callbacks']['early_stopping']['start_from_epoch'],\n",
    "    # mode = 'min', # should be chosen correctly based on monitor value\n",
    ")\n",
    "\n",
    "# Model Checkpoints for saving best model weights\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    os.path.join( run['path'], 'best_model' ),\n",
    "    save_best_only = True,\n",
    "    monitor = 'val_loss',\n",
    "    verbose = 1,\n",
    "    # mode = 'min', # should be chosen correctly based on monitor value\n",
    ")\n",
    "\n",
    "class TimeCallback( tf.keras.callbacks.Callback ):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        metric_name = 'epoch_duration',\n",
    "    ):\n",
    "        self.__epoch_start = None\n",
    "        self.__metric_name = metric_name\n",
    "    \n",
    "    def on_epoch_begin(\n",
    "        self,\n",
    "        epoch,\n",
    "        logs = None,\n",
    "    ):\n",
    "        self.__epoch_start = datetime.datetime.utcnow()\n",
    "        \n",
    "    def on_epoch_end(\n",
    "    ):\n",
    "        logs[ self.__metric_name ] = datetime.datetime.utcnow() - self.__epoch_start\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    tensorboard_callback,\n",
    "    early_stopping_callback,\n",
    "    model_checkpoint_callback,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "229e58bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"id\": \"2023_03_19-16_34_48\",\n",
      "   \"notebook_ver\": \"0.0.1\",\n",
      "   \"path\": \"/media/data/runs/2023_03_19-16_34_48\",\n",
      "   \"batch_size\": 128,\n",
      "   \"max_epochs\": 20,\n",
      "   \"label_smoothing\": 0.1,\n",
      "   \"model\": {\n",
      "      \"learning_rate\": 0.0005,\n",
      "      \"classifier\": {\n",
      "         \"dropout\": 0.33,\n",
      "         \"output_logits\": true\n",
      "      },\n",
      "      \"base\": \"Inception_v3_iNaturalist\"\n",
      "   },\n",
      "   \"dataset\": {\n",
      "      \"downsample\": \"min\",\n",
      "      \"source\": \"gbif\",\n",
      "      \"split_test\": 0.05,\n",
      "      \"split_val\": 0.1,\n",
      "      \"seed_split_test\": 1456402203,\n",
      "      \"seed_split_val\": 2341142523,\n",
      "      \"seed_shuffle\": 951075912142645497\n",
      "   },\n",
      "   \"callbacks\": {\n",
      "      \"early_stopping\": {\n",
      "         \"restore_best_weights\": true\n",
      "      }\n",
      "   },\n",
      "   \"label_mapping_path\": \"/media/data/runs/2023_03_19-16_34_48/label_mapping.json\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print_run_metadata( run )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5b5997ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_run_metadata( run )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "510fdab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1654/1654 [==============================] - ETA: 0s - loss: 7.8494 - accuracy: 0.0010 - auc: 0.5578\n",
      "Epoch 1: val_loss improved from inf to 9.52973, saving model to /media/data/runs/2023_03_19-16_34_48/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) tfhub/google.inaturalist.inception_v3_input with unsupported characters which will be renamed to tfhub_google_inaturalist_inception_v3_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1654/1654 [==============================] - 1450s 854ms/step - loss: 7.8494 - accuracy: 0.0010 - auc: 0.5578 - val_loss: 9.5297 - val_accuracy: 4.2521e-04 - val_auc: 0.5000\n",
      "Epoch 2/20\n",
      "1654/1654 [==============================] - ETA: 0s - loss: 7.4985 - accuracy: 0.0033 - auc: 0.6618\n",
      "Epoch 2: val_loss did not improve from 9.52973\n",
      "1654/1654 [==============================] - 1540s 931ms/step - loss: 7.4985 - accuracy: 0.0033 - auc: 0.6618 - val_loss: 40.1899 - val_accuracy: 3.8269e-04 - val_auc: 0.5003\n",
      "Epoch 3/20\n",
      "1654/1654 [==============================] - ETA: 0s - loss: 7.2587 - accuracy: 0.0085 - auc: 0.7172\n",
      "Epoch 3: val_loss improved from 9.52973 to 8.00553, saving model to /media/data/runs/2023_03_19-16_34_48/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) tfhub/google.inaturalist.inception_v3_input with unsupported characters which will be renamed to tfhub_google_inaturalist_inception_v3_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1654/1654 [==============================] - 1464s 885ms/step - loss: 7.2587 - accuracy: 0.0085 - auc: 0.7172 - val_loss: 8.0055 - val_accuracy: 4.6773e-04 - val_auc: 0.5050\n",
      "Epoch 4/20\n",
      "1654/1654 [==============================] - ETA: 0s - loss: 6.9979 - accuracy: 0.0203 - auc: 0.7499\n",
      "Epoch 4: val_loss did not improve from 8.00553\n",
      "1654/1654 [==============================] - 1450s 877ms/step - loss: 6.9979 - accuracy: 0.0203 - auc: 0.7499 - val_loss: 8.0780 - val_accuracy: 3.8269e-04 - val_auc: 0.5000\n",
      "Epoch 5/20\n",
      "1654/1654 [==============================] - ETA: 0s - loss: 6.7620 - accuracy: 0.0370 - auc: 0.7683\n",
      "Epoch 5: val_loss did not improve from 8.00553\n",
      "1654/1654 [==============================] - 1466s 886ms/step - loss: 6.7620 - accuracy: 0.0370 - auc: 0.7683 - val_loss: 8.2458 - val_accuracy: 3.8269e-04 - val_auc: 0.4981\n",
      "Epoch 6/20\n",
      "1654/1654 [==============================] - ETA: 0s - loss: 6.4970 - accuracy: 0.0634 - auc: 0.7834\n",
      "Epoch 6: val_loss did not improve from 8.00553\n",
      "1654/1654 [==============================] - 1557s 941ms/step - loss: 6.4970 - accuracy: 0.0634 - auc: 0.7834 - val_loss: 8.3081 - val_accuracy: 5.5277e-04 - val_auc: 0.5006\n",
      "Epoch 7/20\n",
      "1654/1654 [==============================] - ETA: 0s - loss: 6.2572 - accuracy: 0.0948 - auc: 0.7932\n",
      "Epoch 7: val_loss did not improve from 8.00553\n",
      "1654/1654 [==============================] - 1663s 1s/step - loss: 6.2572 - accuracy: 0.0948 - auc: 0.7932 - val_loss: 8.3279 - val_accuracy: 5.1025e-04 - val_auc: 0.5031\n",
      "Epoch 8/20\n",
      " 198/1654 [==>...........................] - ETA: 19:56 - loss: 6.1145 - accuracy: 0.1177 - auc: 0.7971\n",
      "\n",
      "Interrupted...\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "timer['train_start'] = time.perf_counter()\n",
    "\n",
    "try:\n",
    "    with strategy.scope():\n",
    "        history = full_model.fit(\n",
    "            ds_idp_train,\n",
    "            validation_data = ds_idp_val,\n",
    "            epochs = run['max_epochs'],\n",
    "            callbacks = callbacks,\n",
    "            # validation_freq=2,\n",
    "        )\n",
    "except KeyboardInterrupt:\n",
    "    print('\\n\\nInterrupted...')\n",
    "    # run['interrupted'] = True\n",
    "else:\n",
    "    print('Completed.')\n",
    "    # run['interrupted'] = False\n",
    "    \n",
    "timer['train_end'] = time.perf_counter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ccc0051c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10756.124112295\n"
     ]
    }
   ],
   "source": [
    "run['time'] = timer['train_end'] - timer['train_start']\n",
    "print(run['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "91731c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12476/3436063570.py:32: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['notebook_ver', 'path', 'model.classifier.output_logits', 'model.base',\n",
      "       'dataset.downsample', 'dataset.source', 'label_mapping_path',\n",
      "       'model.classifier.output_normalize',\n",
      "       'callbacks.early_stopping.monitor'],\n",
      "      dtype='object')]\n",
      "\n",
      "  runs_df.to_hdf( runs_hdf_path, runs_hdf_key )\n"
     ]
    }
   ],
   "source": [
    "save_run_metadata( run )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9ab09e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"id\": \"2023_03_19-16_34_48\",\n",
      "   \"notebook_ver\": \"0.0.1\",\n",
      "   \"path\": \"/media/data/runs/2023_03_19-16_34_48\",\n",
      "   \"batch_size\": 128,\n",
      "   \"max_epochs\": 20,\n",
      "   \"label_smoothing\": 0.1,\n",
      "   \"model\": {\n",
      "      \"learning_rate\": 0.0005,\n",
      "      \"classifier\": {\n",
      "         \"dropout\": 0.33,\n",
      "         \"output_logits\": true\n",
      "      },\n",
      "      \"base\": \"Inception_v3_iNaturalist\"\n",
      "   },\n",
      "   \"dataset\": {\n",
      "      \"downsample\": \"min\",\n",
      "      \"source\": \"gbif\",\n",
      "      \"split_test\": 0.05,\n",
      "      \"split_val\": 0.1,\n",
      "      \"seed_split_test\": 1456402203,\n",
      "      \"seed_split_val\": 2341142523,\n",
      "      \"seed_shuffle\": 951075912142645497\n",
      "   },\n",
      "   \"callbacks\": {\n",
      "      \"early_stopping\": {\n",
      "         \"restore_best_weights\": true\n",
      "      }\n",
      "   },\n",
      "   \"label_mapping_path\": \"/media/data/runs/2023_03_19-16_34_48/label_mapping.json\",\n",
      "   \"time\": 10756.124112295\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print_run_metadata( run )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "829710e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m( \u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mepoch )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "len( history.epoch )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b402c6",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6480267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.concatenate([y for x, y in ds_idp_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e18185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    predictions = full_model.predict(\n",
    "        ds_idp_test,\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4a861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dd26e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8634f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ef0eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc0de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a8224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa88c481",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84161b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c37a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax( predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c16ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax( test_labels, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17eb50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = tf.math.confusion_matrix(\n",
    "    np.argmax( test_labels, axis=1),\n",
    "    np.argmax( predictions, axis=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebff06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.f1_score(\n",
    "    np.argmax( test_labels, axis = 1 ),\n",
    "    np.argmax( predictions, axis = 1 ),\n",
    "    average = 'micro',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5572c52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-fungi]",
   "language": "python",
   "name": "conda-env-.conda-fungi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
